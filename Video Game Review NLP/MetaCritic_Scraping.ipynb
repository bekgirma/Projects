{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba1e28e",
   "metadata": {},
   "source": [
    "### Description\n",
    "Web Scraping tool made using BeautifulSoup. It prompts the user for a video game title and the number of pages it should scrape. Once done it will prompt for another title or the user can also type quit to stop it. The collected data is stored in a csv file named output in the same folder as the code. The data stored in each row is the name of the vidoe game, username of the reviewer, the date it was reviewed, the score given, and the written review. \n",
    "\n",
    "Limitation / Issues of the code\n",
    "-  it only looks for PC game reviews. It should be easy to tweak the URL variable for it to look for video games on different platforms.\n",
    "- naming the video game has to be specific; 'diablo iv' works but 'diablo 4' does not. This issue will not throw an error the prompt will just appear again without anything being collected. I recommend visiting metacritic.com to see how it was written there.\n",
    "- Due to labeling in the html, I wasn't able to find away to scrape the reviews that appear first and last in the web pages.\n",
    "- Foreign languages will be scrapped too. I'm looking into how to only collect english reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cb12250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resident Evil 4\n",
      "What are the number of pages?\n",
      "10\n",
      "Resident Evil 2\n",
      "What are the number of pages?\n",
      "10\n",
      "Resident Evil 3\n",
      "What are the number of pages?\n",
      "10\n",
      "Resident Evil Village\n",
      "What are the number of pages?\n",
      "10\n",
      "Resident Evil 7 Biohazard\n",
      "What are the number of pages?\n",
      "10\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from https://towardsdatascience.com/web-scraping-metacritic-reviews-using-beautifulsoup-63801bbe200e\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "review_dict = {'video game':[],'username':[], 'date':[],'score':[],'review':[]}\n",
    "while True: # While there are still reviews to collect\n",
    "    video_game = input().lower() # Type in the name of a video game\n",
    "    if (video_game == 'quit'): break # Stops collecting reviews if prompted to quit\n",
    "    video_game = video_game.replace(' ', '-').replace(':','').lower() \n",
    "    \n",
    "    print(\"What are the number of pages?\")\n",
    "     # Might not be relevant as giving number of pages exceeding one on website doesn't throw errors\n",
    "    num_pages = int(input())\n",
    "    \n",
    "    for page in range(0,num_pages):\n",
    "        URL = \"https://www.metacritic.com/game/pc/\"+ video_game + \"/user-reviews?sort-by=date&num_items=100&page=\"+str(page)\n",
    "        user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(URL, headers = user_agent)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        for review in soup.find_all('li', class_='review user_review'):\n",
    "            review_dict['video game'].append(video_game)\n",
    "            if review.find('span', class_='blurb blurb_expanded'):\n",
    "                review_dict['review'].append( # Review of game\n",
    "                    review.find('span', class_='blurb blurb_expanded').text)\n",
    "                review_dict['username'].append( # Username of reviewer\n",
    "                    review.find('div', class_='review_critic').find('a').text)\n",
    "                review_dict['date'].append( # Date of the review\n",
    "                    review.find('div', class_='date').text)\n",
    "                review_dict['score'].append( # Score given\n",
    "                    review.find('div', class_='review_grade').find('div').text)\n",
    "            else:\n",
    "                review_dict['review'].append(\n",
    "                    review.find('div',class_='review_body').find('span').text) \n",
    "                review_dict['username'].append(\n",
    "                    review.find('div', class_='review_critic').find('a').text)\n",
    "                review_dict['date'].append(\n",
    "                    review.find('div', class_='date').text)\n",
    "                review_dict['score'].append(\n",
    "                    review.find('div', class_='review_grade').find('div').text)\n",
    "reviews = pd.DataFrame(review_dict)\n",
    "reviews['score'] = [int(x) for x in reviews['score']]\n",
    "reviews['rating'] = ['Negative' if x < 5 else 'Positive' if x > 7\n",
    "                     else 'Average' for x in reviews['score']]\n",
    "reviews.to_csv('output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
